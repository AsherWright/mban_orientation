---
title: "Data Pre-Processing for Machine Learning with Boston AirBnB data"
author: "Colin Pawlowski"
date: "8/28/2018"
output: 
  html_document:
    theme: sandstone
    highlight: tango
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# 0. Introduction
Before we build our predictive models, we need to do a bit of wrangling to prepare our data set.
Since this is a real-world example, we will need to deal with missing values and strange data types.
Our goal will be to create a data frame with one column for the dependent variable,
`price`, and the rest of the columns for the independent variables used to predict `price`, such
as `# of bedrooms`, `# of bathrooms`, etc.  

This file goes over some initial data pre-processing that we did to
prepare the file `listingsML.RDS`, starting from the raw data file
`listings.csv`.  It is not required, but it may be helpful to look over this
file to learn some data wrangling techniques for your future analytics projects in `R`.
In addition, we have shared this code so that our data pipeline is
transparent.  It is important to document the steps in the data
pipelines for all of your projects, so that the analysis can be replicated
by yourself and others.  First, let's read in the data:

```{r readdata}
library(tidyverse)
listingsOrig <- read.csv("../data/listings.csv", stringsAsFactors = FALSE)
```

# 1. Obtaining the Outcome Variable
This is the most important step of the data preparation process, because without historical
data on AirBnB price, we cannot build a predictive model at all.  Recall that the price column
was originally in text format, so let's convert to numeric format.  Because this column is important, let's make it the first column in our data frame.  

```{r price}
listingsML <- listingsOrig %>%
  mutate(price = as.numeric(gsub(",|\\$", "", price))) %>%
  select(price, everything())
```

Let's take a look at our data set now.
```{r glimpseBeforePrep}
glimpse(listingsML)
```

# 2. Converting Data Types of Independent Variables
Just as we differentiate between regression / classification for continuous / categorical
outcome variables, we should differentiate between continuous / categorical independent
variables when preparing our data set for machine learning.  `R` tries to do this automatically
when it reads in the data set, but sometimes it makes mistakes.  For example, `host_response_rate`
should be numeric data type and `last_scraped` should be a date data type.  In addition, \"N\\A\" and \"\" should be marked as missing values.  Let's make these changes, learning some more tidyverse commands in the process:

```{r datatypes}
# Step 1: convert "N/A" and "" to NA values
# Step 2: convert (last_scraped, host_since, first_review, last_review,
#         calendar_last_scraped) to Date format
# Step 3: convert (host_response_rate, host_acceptance_rate,
#         weekly_price, monthly_price, security_deposit,
#         cleaning_fee, extra_people) to numeric format
listingsML <- listingsML %>%
  mutate_all(~na_if(., "N/A")) %>%
  mutate_all(~na_if(., "")) %>%
  mutate_at(vars(last_scraped, host_since, first_review, last_review,
                 calendar_last_scraped), as.Date) %>%
  mutate_at(vars(host_response_rate, host_acceptance_rate,
                 weekly_price, monthly_price, security_deposit,
                 cleaning_fee, extra_people),
            ~as.numeric(gsub("\\%|\\$", "", .)))
```

It looks like most of the columns are in the correct format except for  `amenities`, which we will look at next.  

**Side note about custom functions:** There are few ways to write custom functions in R.
Here is the notation for the function f(x) = x^2.  
```{r func1}
f <- function(x) {
  return(x ^ 2)
}
```

Alternatively, we can write this function more compactly as:
```{r func2}
f <- function(x) x ^ 2
```

In dplyr, another way of writing functions instead of
\"function(x) \<code here with x as a variable\>\" is
\"~ \<code here with . as a variable\>\".  So if we wanted to
square the price column we could write:
```{r func3}
listings2 <- listingsML %>%
  mutate_at(vars(price), ~ . ^ 2)
```

Let's remove these new variables we just created to clean up our
environment:
```{r removeVar}
rm(listings2)
rm(f)
```

# 3. Missing Value Imputation
Missing values are a nuisance which must be handled early on to avoid causing problems downstream
in the data pipeline.  In `R`, missing values take the value `NA`.  They may be caused by a number of different factors, which should influence how we deal with them.  First off, let's check how many missing values are in each column of our data set.  
```{r missingcheck}
listingsML %>%
  is.na() %>%
  colSums() %>%
  sort(decreasing = T)
```

It looks like some columns are missing all 3585 values!  We definitely want to remove these from
our data set, because they are giving no useful information.  Let's remove all columns with 90\% or
more missing values.  For the rest of the columns, we will use missing value imputation to "fill in"
the unknown values with their most likely values.  There are many good R packages
for this, for example `mice` for multiple imputation or `missForest` for random forest imputation.
Here, we will do a simple median imputation. 
```{R missingvalues}
# Step 1: Remove columns with 90% or more missing values
# Step 2: Fill in missing values in numeric columns with the median value
# (We may need to convert integer to numeric types if we impute fractional values)
# Step 3: Fill in missing values in categorical columns with the value "UNKNOWN"
listingsML <- listingsML %>%
  select_if(~sum(is.na(.)) < 0.9 * nrow(listingsOrig)) %>%
  mutate_if(is.integer, as.numeric) %>%
  mutate_if(~is.numeric(.) | is.double(.), ~coalesce(., median(., na.rm = T))) %>%
  mutate_if(is.character, ~coalesce(., "UNKNOWN"))
```

# 4. Expand the Amenities and Host Verifications
Let's take a look at the `amenities` column in the data set.  
```{r amenitiesBefore}
listingsML$amenities[1:3]
```

Although it is listed as a single variable, this is really multiple categorical variables
grouped together.  We will use the following custom-made function to split this into
multiple columns.  
```{r amenitiesFunction}
expand_amenities <- function(listings_df) {
  listings_df <- listings_df %>%
    mutate(amenities = gsub("[{}]|\"|[()]|-", "", paste(amenities))) %>%
    mutate(amenities = gsub(" |/", "_", amenities)) %>%
    mutate(amenities = gsub("24", "x24", amenities)) %>%
    mutate(amenities = gsub("translation_missing:_en.hosting_amenity",
                            "other", amenities))

  splitting <- strsplit(listings_df$amenities, ",")
  all_amenities <- Reduce(union, splitting)
  for (i in all_amenities) {
    listings_df[paste0("amenity_", i)] <- 
      grepl(i, listings_df$amenities)
  }
  return(listings_df)
}
```

We can write a similar function to expand the `host_verifications` column
into multiple columns.
```{r hostVerificationsFunction}
expand_hostVerifications <- function(listings_df) {
  listings_df <- listings_df %>%
    mutate(host_verifications = gsub("'|\\[|\\]| ", "", paste(host_verifications)))

  splitting <- strsplit(listings_df$host_verifications, ",")
  all_verifications <- Reduce(union, splitting)
  for (i in all_verifications) {
    listings_df[paste0("host_", i)] <- 
      grepl(i, listings_df$host_verifications)
  }
  return(listings_df)
}
```

Let's split the columns and take a look:
```{r amenitiesAfter}
listingsML <- listingsML %>%
  expand_amenities() %>%
  expand_hostVerifications()
glimpse(listingsML)
```

We have increased the number of variables from 89 to 147 in the data set, with new features
such as `amenity_TV`, `amenity_Wireless_Internet`, and `amenity_Kitchen`, along with
`host_email`, `host_phone`, and `host_facebook`.  These features
should be predictive of price, so we think that these will improve our machine learning models.  

# 5. Remove Extra Variables
There are some variables, such as `description` and `listing_url`, which are categorical
variables that are not going to be useful in our predictive model because
they have too many or too few levels.  Other variables such as
`weekly_price` and `cleaning_fee` may be highly predictive of price,
but we would like to build models without this information so that it will
be more useful in practice.   Other variables such as `neighborhood` may be removed
because they are redundant (there is a `neighborhood_cleansed` variable).
In this part, let's remove all of the extra independent
variables that we will not include in our machine learning model
to predict price.  
```{r removeExtraVariables}
# Step 1: Remove categorical variables with too many levels
# Step 2: Remove categorical variables with only 1 level
# Step 3: Remove redundant variables
listingsML <- listingsML %>%
  select_if(~!is.character(.) || length(unique(.)) < 100) %>%
  select(-id, -host_id) %>%
  select_if(~length(unique(.)) > 1) %>%
  select(-weekly_price, -security_deposit, -cleaning_fee) %>%
  select(-neighbourhood, -city, -zipcode, -market,
         -smart_location, -host_verifications,
         -host_neighbourhood, -calendar_updated)
glimpse(listingsML)
```

# 6. Creating Factor Variables
Currently, all of our categorical variables are encoded as character data types,
but we would like them to be encoded as factors.  In addition, we would like
to get rid of the very rare categories (those with frequency < 1%) and group them
into a single \"other\" category.  We can do this using the `fct_lump` function.

```{r factorLump}
# Step 1: Convert categorical variables from character to factor data types
# Step 2: Lump least common (< 1% frequency) categories in the factor variables together
#         into one "other" category
listingsML <- listingsML %>%
  mutate_if(is.character, as.factor) %>%
  mutate_if(is.factor, ~fct_lump(., prop = 0.01))
```

# 7. Removing Outliers
This step is not strictly necessary, but we will do it for this example.  
Take a look at the relationship between `listings$accommodates` and `listings$price`. 
```{r outlierPlot}
ggplot(data = listingsML) +
  geom_point(aes(x = accommodates, y = price))
```

Looks like there are some outliers on both axes. There are fancier 
ways to deal with this statistically, but for today let's just get
rid of the outliers, and save a version with the outliers as well.
```{r removeOutliers}
listingsMLwithOutliers <- listingsML
listingsML <- listingsML %>%	
  filter(accommodates <= 10, price <= 1000)
```

# 8. Save the Result
Finally, let's save the pre-processed data sets that we have made.  The best way to save them
are as RDS files, which is a format recognized by `R` and is fast to read/write.  
```{r saveRDS}
saveRDS(listingsMLwithOutliers, "../data/listingsMLwithOutliers.RDS")
saveRDS(listingsML, "../data/listingsML.RDS")
```
